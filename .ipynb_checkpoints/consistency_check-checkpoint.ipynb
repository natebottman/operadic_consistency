{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0b27e6-366e-4b67-a8ae-8d0c422ae6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "KEY = ''\n",
    "client = OpenAI(api_key=KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7966fbd9-8317-4222-95a4-ae6e19481935",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.2\n",
    "MODEL=\"gpt-4o\"\n",
    "\n",
    "TOQ_PROMPT = \"\"\"CONVENTIONS:\n",
    "- Trees/DAGs are oriented from the leaves toward the root.\n",
    "END CONVENTIONS\n",
    "\n",
    "I am going to define some concepts/procedures, and then ask you to perform some of these procedures.\n",
    "\n",
    "DEFINITION 1 (decomposing a question into a tree of questions). Given a question, we can decompose it into a number of sub-questions that need to be answered before answering the full question.\n",
    "\n",
    "For example, suppose I have the question:\n",
    "\n",
    "Q: Who is older, Michael Jordan or Kyle Richardson?\n",
    "\n",
    "I want you break this into a tree of questions:\n",
    "\n",
    "Q1: How old is Michael Jordan? [A1]\n",
    "Q2: How old is Kyle Richardson. [A2]\n",
    "Q3: Which is bigger, A1 or A2?\n",
    "\n",
    "Note that there is an underlying DAG structure: Q1, Q2, and Q3 are the nodes, and there are arrows Q1->Q3 and Q2->Q3.END DEFINITION 1Given a tree of questions, we can \"fuse\" them into a single question. This is essentially the inverse operation of the decomposition process in definition 1.\n",
    "\n",
    "Please put your response into a JSON with a field \"questions\" as below:\n",
    "{\n",
    "   \"Questions\" : [\"Q1: How old is Michael Jordan? [A1]\" , \"Q2: How old is Kyle Richardson. [A2]\", ...]\n",
    "}\n",
    "Please don't refer to previous questions when writing new questions. We want to later be able to answer these questions independently from one another.\"\"\"\n",
    "\n",
    "COLLAPSE_PROMPT=\"\"\"\n",
    "TODO\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "ANSWER_PROMPT=\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def call_llm(system_prompt, query, num_retries=5) -> dict:\n",
    "\n",
    "    for attempt in range(num_retries):\n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=MODEL,\n",
    "                input=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": query},\n",
    "                ],\n",
    "                temperature=TEMPERATURE,\n",
    "                )\n",
    "\n",
    "            # For the Responses API\n",
    "            text = response.output[0].content[0].text\n",
    "\n",
    "            json_parse = json.loads(text)\n",
    "            return json_parse\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Attempt {attempt + 1}/{num_retries}] ERROR: {e}\")\n",
    "\n",
    "    print(\"All retries failed. Returning empty dict.\")\n",
    "    return {}\n",
    "\n",
    "def get_subquestions(question: str):\n",
    "    llm_output = call_llm(TOQ_PROMPT, question)\n",
    "    return llm_output[\"Questions\"]\n",
    "\n",
    "def get_collapses(subquestions: list):\n",
    "    ### direct version\n",
    "    squestions = '\\n'.join(subquestions)\n",
    "    llm_output = call_llm(COLLAPSE_PROMPT, squestions)\n",
    "    return llm_output[\"Questions\"]\n",
    "   \n",
    "def answer_question(toq):\n",
    "    llm_output = call_llm(ANSWER_PROMPT, toq)\n",
    "    return llm_output[\"Answers\"]\n",
    "   \n",
    "def model(question):\n",
    "    subquestions: list = get_subquestions(question)\n",
    "    collapses: list = get_collapses(subquestions)\n",
    "    collapsed_answers = answer_question(collapses)\n",
    "\n",
    "    return collapsed_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea32f5a-f384-4078-88c9-f276be61e6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q1: What are the characteristics of a dog breed that make it suitable for an older adult? [A1]',\n",
       " 'Q2: What are some dog breeds known for being low maintenance? [A2]',\n",
       " 'Q3: What are some dog breeds known for being friendly and gentle? [A3]',\n",
       " 'Q4: Which dog breeds are known for being good companions for older adults? [A4]',\n",
       " 'Q5: Based on A1, A2, A3, and A4, what is the best breed of dog for an older adult?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_subquestions(\"What is the best breed of dog for an older adult?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb8fe1-8558-4175-af41-90a38f227f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
